{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNNs) for the Regression Problem\n",
    "\n",
    "In this notebook, we build a Recurrent Neural Networks (RNNs) using GloVe word embeddings, to predict the __log_votes__ field of our review dataset.\n",
    "\n",
    "Overall dataset schema:\n",
    "* __reviewText:__ Text of the review\n",
    "* __summary:__ Summary of the review\n",
    "* __verified:__ Whether the purchase was verified (True or False)\n",
    "* __time:__ UNIX timestamp for the review\n",
    "* __rating:__ Rating of the review\n",
    "* __log_votes:__ Logarithm-adjusted votes log(1+votes)\n",
    "\n",
    "__Important note:__ One big distinction betweeen the regular neural networks and RNNs is that RNNs work with sequential data. In our case, RNNs will help us with the text field. If we also want to consider other fields such as time, rating, verified, etc. , we need to use the regular neural networks and connect it to the RNN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import d2l\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, np, npx\n",
    "from mxnet.gluon import nn, rnn\n",
    "\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the dataset below and fill-in the reviewText field. We will use this field as input to our ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../DATA/NLP/EMBK-NLP-REVIEW-DATA-CSV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first five rows in the dataset. As you can see the __log_votes__ field is numeric. That's why we will build a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>log_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuck with this at work, slow and we still got...</td>\n",
       "      <td>Use SEP or Mcafee</td>\n",
       "      <td>False</td>\n",
       "      <td>1464739200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I use parallels every day with both my persona...</td>\n",
       "      <td>Use it daily</td>\n",
       "      <td>False</td>\n",
       "      <td>1332892800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbara Robbins\\n\\nI've used TurboTax to do ou...</td>\n",
       "      <td>Helpful Product</td>\n",
       "      <td>True</td>\n",
       "      <td>1398816000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have been using this software security for y...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>True</td>\n",
       "      <td>1430784000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you want your computer hijacked and slowed ...</td>\n",
       "      <td>... hijacked and slowed to a crawl Windows 10 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1508025600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Stuck with this at work, slow and we still got...   \n",
       "1  I use parallels every day with both my persona...   \n",
       "2  Barbara Robbins\\n\\nI've used TurboTax to do ou...   \n",
       "3  I have been using this software security for y...   \n",
       "4  If you want your computer hijacked and slowed ...   \n",
       "\n",
       "                                             summary  verified        time  \\\n",
       "0                                  Use SEP or Mcafee     False  1464739200   \n",
       "1                                       Use it daily     False  1332892800   \n",
       "2                                    Helpful Product      True  1398816000   \n",
       "3                                         Five Stars      True  1430784000   \n",
       "4  ... hijacked and slowed to a crawl Windows 10 ...     False  1508025600   \n",
       "\n",
       "   rating  log_votes  \n",
       "0     1.0        0.0  \n",
       "1     5.0        0.0  \n",
       "2     4.0        0.0  \n",
       "3     5.0        0.0  \n",
       "4     1.0        0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis and Missing Value Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the range and distribution of log_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"log_votes\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.799753318287247"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum = df[\"log_votes\"].max()\n",
    "maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"log_votes\"].plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of missing values for each columm below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText    6\n",
      "summary       7\n",
      "verified      0\n",
      "time          0\n",
      "rating        0\n",
      "log_votes     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only consider the reviewText field. Let's fill-in the missing values for that below. We will just use the placeholder \"Missing\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reviewText\"].fillna(\"Missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the review texts to be fed into the deep learning model by:\n",
    "- Reserving 15% of the dataset as a validation dataset\n",
    "- Padding and truncating the data to the length of 50 words\n",
    "- Converting the encoded text into into MXNet's ndarray format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This separates 15% of the entire dataset into test dataset.\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(df[\"reviewText\"], df[\"log_votes\"].tolist(), \n",
    "                     test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X_train, X_test, y_train, y_test, num_steps=50):\n",
    "    ## num_steps=50 trim the sentence after the 50th word\n",
    "    \n",
    "    train_tokens = d2l.tokenize(X_train, token='word')\n",
    "    test_tokens = d2l.tokenize(X_test, token='word')\n",
    "    vocab = d2l.Vocab(train_tokens, min_freq=5)\n",
    "    \n",
    "    ## convert to ndarray\n",
    "    train_features = np.array([d2l.trim_pad(vocab[line], num_steps, vocab.unk)\n",
    "                               for line in train_tokens], dtype=np.float32)\n",
    "    test_features = np.array([d2l.trim_pad(vocab[line], num_steps, vocab.unk)\n",
    "                              for line in test_tokens], dtype=np.float32)  ## l2_loss does not accept float64\n",
    "    y_train = np.array(y_train, dtype=np.float32).reshape(-1, 1)\n",
    "    y_test = np.array(y_test, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "    return train_features, test_features, y_train, y_test, vocab\n",
    "\n",
    "truncate_word_after_max = 50\n",
    "train_features, test_features, train_labels, test_labels, vocab = \\\n",
    "    load_data(X_train, X_test, y_train, y_test, truncate_word_after_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using pre-trained GloVe Word Embeddings:\n",
    "\n",
    "In this example, we will use GloVe word vectors. The following code shows how to get the word vectors and create an embedding dictionary using Gluon. The dictionary maps the words to their word vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.817147731781006\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from mxnet.contrib import text\n",
    "glove_embedding = text.embedding.create('glove', pretrained_file_name='glove.6B.300d.txt')\n",
    "embedding_matrix = glove_embedding.get_vecs_by_tokens(vocab.idx_to_token)\n",
    "embedding_matrix.shape\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "#### Initializing the model\n",
    "After all the data and word vector preparation, now is the time to define the model and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context, num_hidden = mx.cpu(), 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a simple model:\n",
    "1. Initializing with a `Sequential()` block, which can be added a series architecture;\n",
    "1. One embedding layer with the shape of `embedding_matrix` from Glove;\n",
    "1. One `RNN` block with `num_hidden` hidden states, and a input layout 'NTC', where (T, N, C) stand for (sequence length, batch size, word vector dimensions) respectively;\n",
    "1. One `Dense` layer with activation function ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Embedding(23421 -> 300, float32)\n",
       "  (1): RNN(-1 -> 100, NTC)\n",
       "  (2): Dense(-1 -> 1, Activation(relu))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add(nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1]),\n",
    "          rnn.RNN(num_hidden, layout = 'NTC'),        \n",
    "          nn.Dense(1, activation='relu')              # Output layer\n",
    "         )\n",
    "\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx=context)\n",
    "model[0].weight.set_data(embedding_matrix)\n",
    "model[0].collect_params().setattr('grad_req', 'null')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the `train()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, batch_size):\n",
    "    l2_loss = gluon.loss.L2Loss() \n",
    "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
    "    test_iter = d2l.load_array((test_features, test_labels), batch_size)\n",
    "    # The SGD optimization algorithm is used here\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', \n",
    "                            {'learning_rate': learning_rate})\n",
    "    for epoch in range(num_epochs):\n",
    "        train_ls, test_ls = 0, 0\n",
    "        for X, y in train_iter:\n",
    "#             print(X.shape) # (64, 50)\n",
    "            with autograd.record():\n",
    "                out = net(X)\n",
    "                l = l2_loss(out, y)\n",
    "                \n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_ls += l.sum()        \n",
    "        \n",
    "        for test_X, test_y in test_iter:\n",
    "            test_ls += l2_loss(net(test_X), test_y).sum()\n",
    "            \n",
    "        # Let's take the average losses\n",
    "        training_loss = train_ls / len(train_labels)\n",
    "        val_loss = test_ls / len(test_labels)\n",
    "        print(\"Epoch %s. Train_loss (mse) %s Validation_loss (mse) %s\" % (epoch, training_loss, val_loss))\n",
    "    return training_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "Before we execute the training loop, we need to define a function that will calculate the accurary metrics for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mse(data_iterator, net, ctx=mx.cpu()):\n",
    "    metric = mx.metric.MSE()\n",
    "    data_iterator.reset()\n",
    "    for i, batch in enumerate(data_iterator):\n",
    "        data1 = batch.data[0].as_in_context(ctx)\n",
    "        data2 = batch.data[1].as_in_context(ctx)\n",
    "        data = [data1, data2]\n",
    "        label = batch.label[0].as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        metric.update([label], [output])\n",
    "    return metric.get()[1]\n",
    "\n",
    "def evaluate_accuracy(data_iterator, net, ctx=mx.cpu()):\n",
    "    metric = mx.metric.MSE()\n",
    "    data_iterator.reset()\n",
    "    for i, batch in enumerate(data_iterator):\n",
    "        data1 = batch.data[0].as_in_context(ctx)\n",
    "        data2 = batch.data[1].as_in_context(ctx)\n",
    "        data = [data1, data2]\n",
    "        label = batch.label[0].as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        metric.update([label], [output])\n",
    "    return metric.get()[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training \n",
    "Let's start the training process below. We will print Mean Squared Error after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train_loss (mse) 0.4002086 Validation_loss (mse) 0.41561332\n",
      "Epoch 1. Train_loss (mse) 0.3708301 Validation_loss (mse) 0.40098622\n",
      "Epoch 2. Train_loss (mse) 0.35947812 Validation_loss (mse) 0.39977625\n",
      "Epoch 3. Train_loss (mse) 0.35130775 Validation_loss (mse) 0.40115747\n",
      "Epoch 4. Train_loss (mse) 0.3433983 Validation_loss (mse) 0.40528333\n",
      "Epoch 5. Train_loss (mse) 0.3365414 Validation_loss (mse) 0.40687948\n",
      "Epoch 6. Train_loss (mse) 0.3310842 Validation_loss (mse) 0.40278947\n",
      "Epoch 7. Train_loss (mse) 0.32480574 Validation_loss (mse) 0.41070834\n",
      "Epoch 8. Train_loss (mse) 0.31928474 Validation_loss (mse) 0.4053369\n",
      "Epoch 9. Train_loss (mse) 0.3137251 Validation_loss (mse) 0.4100854\n",
      "100.64318013191223\n"
     ]
    }
   ],
   "source": [
    "learning_rate, epochs, batch_size = 0.01, 10, 64\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train(net=model, train_features=train_features, train_labels=train_labels, \n",
    "      test_features=test_features, test_labels=test_labels,\n",
    "      num_epochs=epochs, learning_rate=learning_rate, \n",
    "      batch_size=batch_size)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "423.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
