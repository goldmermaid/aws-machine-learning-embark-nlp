{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Day 3 Solution: Neural Networks and Transformers  for a Classification Task\n",
    "\n",
    "We continue to work with the final project dataset to see how Recurrent Neural Networks (RNNs), Long Short-term Memory Networks (LSTMs) and Transformers, perform to predict the __isPositive__ field of the dataset.\n",
    "\n",
    "* We are giving you two pieces of code to read your training and test datasets.\n",
    "* Use the notebooks from the class and implement the model, train and test with the corresponding datasets.\n",
    "\n",
    "*Note: Incorporate all that you have learned over Day 1 and Day 2. Feel free to use your processed data from Day 1 to save on redundant work.*\n",
    "\n",
    "Overall dataset schema:\n",
    "* __reviewText:__ Text of the review\n",
    "* __summary:__ Summary of the review\n",
    "* __verified:__ Whether the purchase was verified (True or False)\n",
    "* __time:__ UNIX timestamp for the review\n",
    "* __log_votes:__ Logarithm-adjusted votes log(1+votes)\n",
    "* __isPositive:__ Rating of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import d2l\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, np, npx, autograd\n",
    "from mxnet.gluon import nn, rnn\n",
    "\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the datasets below and fill-in the reviewText field. We will use this field as input to our ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('../../DATA/NLP/EMBK-NLP-FINAL-TRAIN-CSV.csv')\n",
    "df_test = pd.read_csv('../../DATA/NLP/EMBK-NLP-FINAL-TEST-CSV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first five rows in the datasets. As you can see the __log_votes__ field is numeric. That's why we will build a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>time</th>\n",
       "      <th>log_votes</th>\n",
       "      <th>isPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO...</td>\n",
       "      <td>IDEAL FOR BEGINNER!</td>\n",
       "      <td>True</td>\n",
       "      <td>1361836800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unable to open or use</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>True</td>\n",
       "      <td>1452643200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waste of money!!! It wouldn't load to my system.</td>\n",
       "      <td>Dont buy it!</td>\n",
       "      <td>True</td>\n",
       "      <td>1433289600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I attempted to install this OS on two differen...</td>\n",
       "      <td>I attempted to install this OS on two differen...</td>\n",
       "      <td>True</td>\n",
       "      <td>1518912000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've spent 14 fruitless hours over the past tw...</td>\n",
       "      <td>Do NOT Download.</td>\n",
       "      <td>True</td>\n",
       "      <td>1441929600</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO...   \n",
       "1                              unable to open or use   \n",
       "2   Waste of money!!! It wouldn't load to my system.   \n",
       "3  I attempted to install this OS on two differen...   \n",
       "4  I've spent 14 fruitless hours over the past tw...   \n",
       "\n",
       "                                             summary  verified        time  \\\n",
       "0                                IDEAL FOR BEGINNER!      True  1361836800   \n",
       "1                                          Two Stars      True  1452643200   \n",
       "2                                       Dont buy it!      True  1433289600   \n",
       "3  I attempted to install this OS on two differen...      True  1518912000   \n",
       "4                                   Do NOT Download.      True  1441929600   \n",
       "\n",
       "   log_votes  isPositive  \n",
       "0   0.000000         1.0  \n",
       "1   0.000000         0.0  \n",
       "2   0.000000         0.0  \n",
       "3   0.000000         0.0  \n",
       "4   1.098612         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>time</th>\n",
       "      <th>log_votes</th>\n",
       "      <th>isPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaspersky offers the best security for your co...</td>\n",
       "      <td>State of the art protection</td>\n",
       "      <td>True</td>\n",
       "      <td>1465516800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This Value was extremely discounted which I ap...</td>\n",
       "      <td>Quickbooks</td>\n",
       "      <td>True</td>\n",
       "      <td>1393632000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some dufus probably got stock options by the t...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>False</td>\n",
       "      <td>1228176000</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have reviewed the software and it is beyond ...</td>\n",
       "      <td>Excellent product</td>\n",
       "      <td>True</td>\n",
       "      <td>1402531200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plain old simple you need Anti-Virus,I have tr...</td>\n",
       "      <td>A must have</td>\n",
       "      <td>True</td>\n",
       "      <td>1367539200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Kaspersky offers the best security for your co...   \n",
       "1  This Value was extremely discounted which I ap...   \n",
       "2  Some dufus probably got stock options by the t...   \n",
       "3  I have reviewed the software and it is beyond ...   \n",
       "4  Plain old simple you need Anti-Virus,I have tr...   \n",
       "\n",
       "                       summary  verified        time  log_votes  isPositive  \n",
       "0  State of the art protection      True  1465516800   0.000000         1.0  \n",
       "1                   Quickbooks      True  1393632000   0.000000         1.0  \n",
       "2                          Sad     False  1228176000   2.639057         0.0  \n",
       "3            Excellent product      True  1402531200   0.000000         1.0  \n",
       "4                  A must have      True  1367539200   0.000000         1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis and Missing Value Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the target distribution for our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    43692\n",
       "0.0    26308\n",
       "Name: isPositive, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"isPositive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4980\n",
       "0.0    3020\n",
       "Name: isPositive, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"isPositive\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText    11\n",
      "summary       14\n",
      "verified       0\n",
      "time           0\n",
      "log_votes      0\n",
      "isPositive     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText    2\n",
      "summary       1\n",
      "verified      0\n",
      "time          0\n",
      "log_votes     0\n",
      "isPositive    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only consider the reviewText field. Let's fill-in the missing values for that below. We will just use the placeholder \"Missing\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"reviewText\"].fillna(\"Missing\", inplace=True)\n",
    "df_test[\"reviewText\"].fillna(\"Missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text processing-cleaning\n",
    "\n",
    "Next, we will clean the text. We will remove leading/train white space, extra space and html tags. Recurrent neural networks usually __DON'T__ need text processing work further than simple text cleaning. Stemming and lemmatization can introduce some errors that will cause our model to skip those words completely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some string preprocessing\n",
    "def clean_str(text):\n",
    "    text = text.lower().strip() # Remove leading/trailing whitespace\n",
    "    text = re.sub('\\s+', ' ', text) # Remove extra space and tabs\n",
    "    text = re.compile('<.*?>').sub('', text) # Remove HTML tags/markups:\n",
    "    return text\n",
    "\n",
    "clean_reviews_train = [clean_str(x) for x in df_train[\"reviewText\"].tolist()]\n",
    "clean_reviews_test = [clean_str(x) for x in df_test[\"reviewText\"].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the review texts to be fed into the deep learning model by (1) Reserving 15% of the dataset as a validation dataset, (2) padding and truncating the data to the length of 50 words, and (3) converting the encoded text into into MXNet's NDArray format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This separates 15% of the entire dataset into val dataset.\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(clean_reviews_train, df_train[\"isPositive\"].tolist(), \n",
    "                     test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X_train, X_val, y_train, y_val, num_steps=50):\n",
    "    ## num_steps=50 trim the sentence after the 50th word\n",
    "    \n",
    "    train_tokens = d2l.tokenize(X_train, token='word')\n",
    "    val_tokens = d2l.tokenize(X_val, token='word')\n",
    "    vocab = d2l.Vocab(train_tokens, min_freq=5)\n",
    "    \n",
    "    ## convert to ndarray\n",
    "    train_features = np.array([d2l.trim_pad(vocab[line], num_steps, vocab.unk)\n",
    "                               for line in train_tokens], dtype=np.float32)\n",
    "    val_features = np.array([d2l.trim_pad(vocab[line], num_steps, vocab.unk)\n",
    "                              for line in val_tokens], dtype=np.float32)  ## l2_loss does not accept float64\n",
    "    y_train = np.array(y_train, dtype=np.float32)\n",
    "    y_val = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "    return train_features, val_features, y_train, y_val, vocab\n",
    "\n",
    "truncate_word_after_max = 50\n",
    "train_features, val_features, train_labels, val_labels, vocab = \\\n",
    "    load_data(X_train, X_val, y_train, y_val, truncate_word_after_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-trained GloVe Word Embeddings:\n",
    "\n",
    "In this example, we will use GloVe word vectors. The following code shows how to get the word vectors and create an embedding dictionary using Gluon. The dictionary maps the words to their word vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24986, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet.contrib import text\n",
    "glove_embedding = text.embedding.create('glove', pretrained_file_name='glove.6B.300d.txt')\n",
    "embedding_matrix = glove_embedding.get_vecs_by_tokens(vocab.idx_to_token)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "#### Initializing the model\n",
    "After all the data and word vector preparation, now is the time to define the model and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "context, num_hidden = mx.cpu(), 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a simple model:\n",
    "1. Initializing with a `Sequential()` block, which can be added a series architecture;\n",
    "1. One embedding layer with the shape of `embedding_matrix` from Glove;\n",
    "1. One `RNN` block with `num_hidden` hidden states, and a input layout 'NTC', where (T, N, C) stand for (sequence length, batch size, word vector dimensions) respectively;\n",
    "1. One `Dense` layer with activation function ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Embedding(24986 -> 300, float32)\n",
       "  (1): RNN(-1 -> 100, NTC)\n",
       "  (2): Dense(-1 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize(input_dim, output_dim, num_hidden, context):\n",
    "    model = nn.Sequential()\n",
    "    model.add(nn.Embedding(input_dim, output_dim),\n",
    "              rnn.RNN(num_hidden, layout = 'NTC'),        \n",
    "              nn.Dense(2)              # Output layer\n",
    "              )\n",
    "\n",
    "    model.collect_params().initialize(mx.init.Xavier(), ctx=context)\n",
    "    model[0].weight.set_data(embedding_matrix)\n",
    "    model[0].collect_params().setattr('grad_req', 'null')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = initialize(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
    "                   num_hidden, context)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "Let's define a function that will calculate the accurary metrics for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, loader, context=mx.cpu()):\n",
    "    wrong = 0\n",
    "    total = 0\n",
    "    for _, (data, target) in enumerate(loader):\n",
    "        \n",
    "        data = data.as_in_context(context)\n",
    "        target = target.as_in_context(context)\n",
    "        predictions = np.argmax(model(data), axis=1)\n",
    "        wrong += np.abs(predictions, target).sum()\n",
    "        total += data.shape[0]\n",
    "    \n",
    "    return float(1 - wrong/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the `train()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, val_features, val_labels,\n",
    "          num_epochs, learning_rate, batch_size):\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
    "    val_iter = d2l.load_array((val_features, val_labels), batch_size)\n",
    "    # The SGD optimization algorithm is used here\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', \n",
    "                            {'learning_rate': learning_rate})\n",
    "    for epoch in range(num_epochs):\n",
    "        train_ls, val_ls = 0, 0\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                out = net(X)\n",
    "                y = y.reshape((-1,))\n",
    "                l = softmax_cross_entropy(out, y)\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_ls += l.sum()        \n",
    "        \n",
    "        for val_X, val_y in val_iter:\n",
    "            val_ls += softmax_cross_entropy(net(val_X), val_y).sum()\n",
    "            \n",
    "        # Let's take the average losses\n",
    "        training_loss = train_ls / len(train_labels)\n",
    "        val_loss = val_ls / len(val_labels)\n",
    "        print(\"Epoch %s. Train_loss (mse) %s Validation_loss (mse) %s\" % \\\n",
    "              (epoch, training_loss, val_loss))\n",
    "            \n",
    "    # Calculating training and validation accuracy\n",
    "    train_accuracy = evaluate_accuracy(net, train_iter)\n",
    "    val_accuracy = evaluate_accuracy(net, val_iter)\n",
    "    return net, train_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training \n",
    "Let's start the training process below. We will print Mean Squared Error after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train_loss (mse) 0.59695274 Validation_loss (mse) 0.5375231\n",
      "Epoch 1. Train_loss (mse) 0.51408947 Validation_loss (mse) 0.4935246\n",
      "Epoch 2. Train_loss (mse) 0.482084 Validation_loss (mse) 0.47253278\n",
      "Epoch 3. Train_loss (mse) 0.45635378 Validation_loss (mse) 0.47566172\n",
      "Epoch 4. Train_loss (mse) 0.43796033 Validation_loss (mse) 0.44435388\n",
      "Epoch 5. Train_loss (mse) 0.42355752 Validation_loss (mse) 0.451506\n",
      "Epoch 6. Train_loss (mse) 0.41417316 Validation_loss (mse) 0.42983395\n",
      "Epoch 7. Train_loss (mse) 0.4048757 Validation_loss (mse) 0.43024126\n",
      "Epoch 8. Train_loss (mse) 0.39600328 Validation_loss (mse) 0.4245714\n",
      "Epoch 9. Train_loss (mse) 0.3883114 Validation_loss (mse) 0.41779023\n"
     ]
    }
   ],
   "source": [
    "learning_rate, epochs, batch_size = 0.01, 10, 64\n",
    "\n",
    "# initializing\n",
    "model = initialize(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
    "                   num_hidden, context)\n",
    "\n",
    "# training\n",
    "model_out, train_accuracy, val_accuracy = \\\n",
    "    train(net=model, train_features=train_features, \n",
    "          train_labels=train_labels, \n",
    "          val_features=val_features, val_labels=val_labels,\n",
    "          num_epochs=epochs, learning_rate=learning_rate, \n",
    "          batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34324997663497925"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = clean_reviews_test\n",
    "y_test = df_test[\"isPositive\"].tolist()\n",
    "\n",
    "test_tokens = d2l.tokenize(X_test, token='word')\n",
    "test_features = np.array([d2l.trim_pad(vocab[line], truncate_word_after_max, vocab.unk)\n",
    "                           for line in test_tokens], dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "test_iter = d2l.load_array((test_features, y_test), batch_size)\n",
    "\n",
    "evaluate_accuracy(model_out, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
