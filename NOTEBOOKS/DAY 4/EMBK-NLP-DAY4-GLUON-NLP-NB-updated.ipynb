{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [AutoGluon](https://autogluon.mxnet.io/) TabularPrediction for a Regression Problem \n",
    "\n",
    "In this notebook, we will see how __AutoGluon TabularPrediction__ works on our regression problem to predict the __log_votes__ field of our review dataset, using:\n",
    "* TabularPrediction from here: https://autogluon.mxnet.io/tutorials/tabular_prediction/index.html\n",
    "\n",
    "Via a simple __fit()__ call, __AutoGluon TabularPrediction__ can produce a highly-accurate model to predict the values in the __log_votes__ column of our data table based on the rest of the columns’ values. \n",
    "\n",
    "__AutoGluon__ with tabular data works for both classification and regression problems. Moreover, we do not need to specify the kind of problem, as this it automatically inferred from the data and the appropriate performance metric is reported (by default, RMSE for regression, and accuracy for classification).\n",
    "\n",
    "__AutoGluon__ also automatically decides which variables should be represented as integers, which variables should be represented as categorical objects, and handles common issues like missing data and rescaling feature values.\n",
    "\n",
    "Rather than just a single model, __AutoGluon__ trains multiple models and ensembles them together to ensure superior predictive performance. Each type of model has various hyperparameters, which traditionally, the user would have to specify. __AutoGluon__ automates this process, including cross-validation, so there is no need to specify separate validation data.\n",
    "\n",
    "Overall dataset schema:\n",
    "* __reviewText:__ Text of the review\n",
    "* __summary:__ Summary of the review\n",
    "* __verified:__ Whether the purchase was verified (True or False)\n",
    "* __time:__ UNIX timestamp for the review\n",
    "* __rating:__ Rating of the review\n",
    "* __log_votes:__ Logarithm-adjusted votes log(1+votes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup the AutoGluon environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 981kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.1.1\n",
      "    Uninstalling pip-19.1.1:\n",
      "      Successfully uninstalled pip-19.1.1\n",
      "Successfully installed pip-20.0.2\n",
      "Requirement already satisfied: mxnet in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (1.6.0b20190915)\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-0.0.5-py3-none-any.whl (328 kB)\n",
      "\u001b[K     |████████████████████████████████| 328 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from mxnet) (2.22.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from mxnet) (1.17.2)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: tornado>=5.0.1 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from autogluon) (6.0.3)\n",
      "Collecting paramiko>=2.5.0\n",
      "  Downloading paramiko-2.7.1-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.3.3\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl (28.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.4 MB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting boto3==1.9.187\n",
      "  Downloading boto3-1.9.187-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gluoncv>=0.5.0 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from autogluon) (0.5.0)\n",
      "Collecting catboost\n",
      "  Downloading catboost-0.21-cp37-none-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (10.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.7 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lightgbm==2.3.0\n",
      "  Downloading lightgbm-2.3.0-py2.py3-none-macosx_10_8_x86_64.macosx_10_9_x86_64.macosx_10_10_x86_64.macosx_10_11_x86_64.macosx_10_12_x86_64.macosx_10_13_x86_64.macosx_10_14_x86_64.whl (678 kB)\n",
      "\u001b[K     |████████████████████████████████| 678 kB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting distributed==2.6.0\n",
      "  Downloading distributed-2.6.0-py3-none-any.whl (560 kB)\n",
      "\u001b[K     |████████████████████████████████| 560 kB 17.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gluonnlp==0.8.1\n",
      "  Downloading gluonnlp-0.8.1.tar.gz (236 kB)\n",
      "\u001b[K     |████████████████████████████████| 236 kB 23.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dask==2.6.0\n",
      "  Downloading dask-2.6.0-py3-none-any.whl (760 kB)\n",
      "\u001b[K     |████████████████████████████████| 760 kB 19.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil>=5.0.0\n",
      "  Downloading psutil-5.6.7.tar.gz (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==0.21.2\n",
      "  Downloading scikit_learn-0.21.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (10.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5 MB 17.4 MB/s eta 0:00:01    |███████████▏                    | 3.7 MB 17.4 MB/s eta 0:00:01     |███████████████████████▋        | 7.7 MB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.7.1-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 5.5 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting ConfigSpace<=0.4.10\n",
      "  Downloading ConfigSpace-0.4.10.tar.gz (882 kB)\n",
      "\u001b[K     |████████████████████████████████| 882 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow<=6.2.1 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from autogluon) (6.2.1)\n",
      "Collecting cython\n",
      "  Downloading Cython-0.29.15-cp37-cp37m-macosx_10_9_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from autogluon) (3.1.1)\n",
      "Collecting cryptography>=2.8\n",
      "  Downloading cryptography-2.8-cp34-abi3-macosx_10_6_intel.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.38.0\n",
      "  Downloading tqdm-4.42.1-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas<1.0,>=0.24.0 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from autogluon) (0.25.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.1.7-cp34-abi3-macosx_10_6_intel.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 3.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.3.0-cp34-abi3-macosx_10_6_intel.whl (284 kB)\n",
      "\u001b[K     |████████████████████████████████| 284 kB 17.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from boto3==1.9.187->autogluon) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.187 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from boto3==1.9.187->autogluon) (1.12.244)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from boto3==1.9.187->autogluon) (0.9.4)\n",
      "Requirement already satisfied: six in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from catboost->autogluon) (1.12.0)\n",
      "Requirement already satisfied: plotly in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from catboost->autogluon) (4.4.1)\n",
      "Collecting tblib\n",
      "  Downloading tblib-1.6.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting cloudpickle>=0.2.2\n",
      "  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyyaml in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from distributed==2.6.0->autogluon) (5.1.2)\n",
      "Requirement already satisfied: click>=6.6 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from distributed==2.6.0->autogluon) (7.0)\n",
      "Collecting toolz>=0.7.4\n",
      "  Downloading toolz-0.10.0.tar.gz (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 7.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.1.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting zict>=0.1.3\n",
      "  Downloading zict-1.0.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting msgpack\n",
      "  Downloading msgpack-0.6.2-cp37-cp37m-macosx_10_14_x86_64.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 5.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 13.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyaml\n",
      "  Downloading pyaml-19.12.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from ConfigSpace<=0.4.10->autogluon) (2.4.0)\n",
      "Collecting typing\n",
      "  Downloading typing-3.7.4.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from matplotlib->autogluon) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from matplotlib->autogluon) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from matplotlib->autogluon) (0.10.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp37-cp37m-macosx_10_9_x86_64.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from pandas<1.0,>=0.24.0->autogluon) (2019.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.187->boto3==1.9.187->autogluon) (0.15.2)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from plotly->catboost->autogluon) (1.3.3)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: setuptools in /Users/rlhu/miniconda3/envs/d2l/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->autogluon) (41.0.1)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.19.tar.gz (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gluonnlp, psutil, ConfigSpace, toolz, pycparser\n",
      "  Building wheel for gluonnlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gluonnlp: filename=gluonnlp-0.8.1-py3-none-any.whl size=293520 sha256=ccff06b938d447619d6bb6ab2474f2f69a5b37279cfd4fb905a359ce14300759\n",
      "  Stored in directory: /Users/rlhu/Library/Caches/pip/wheels/04/c6/2f/fed73b370eadabfe8809fc8c19b657a4eb4d71228c7ce17a45\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.6.7-cp37-cp37m-macosx_10_7_x86_64.whl size=227611 sha256=a37104a5fd0e55a319d765fff353368a9daa81b7a9c92d1442de1cef99d6de74\n",
      "  Stored in directory: /Users/rlhu/Library/Caches/pip/wheels/65/eb/7c/a2480f4fb514230c9c7c56f31fb34227f0050552c39edab94c\n",
      "  Building wheel for ConfigSpace (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.10-cp37-cp37m-macosx_10_7_x86_64.whl size=864390 sha256=d3add6c32b4b8c0c2b6b76c8f2ab35ae0d05d8897fff4ea53de1d00b5081e0a3\n",
      "  Stored in directory: /Users/rlhu/Library/Caches/pip/wheels/c1/57/66/dfb28c9c2c10697b3bb46355e7f69c5d0591c547c98ba1b6d2\n",
      "  Building wheel for toolz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for toolz: filename=toolz-0.10.0-py3-none-any.whl size=55575 sha256=6bd9469c0f98467a359b6a20dfc037320636e23a7dbffcf764f5d46bfbd3574c\n",
      "  Stored in directory: /Users/rlhu/Library/Caches/pip/wheels/e2/83/7c/248063997a4f9ff6bf145822e620e8c37117a6b4c765584077\n",
      "  Building wheel for pycparser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycparser: filename=pycparser-2.19-py2.py3-none-any.whl size=111031 sha256=66e8b7250e34093ec42c2d87a68b5e1f7e7a08d4d318d2a5774f998d18c1be07\n",
      "  Stored in directory: /Users/rlhu/Library/Caches/pip/wheels/0e/53/27/fee7fd9562e10dd046caccfc0340b8cf789b46846e660f3380\n",
      "Successfully built gluonnlp psutil ConfigSpace toolz pycparser\n",
      "Installing collected packages: pycparser, cffi, bcrypt, pynacl, cryptography, paramiko, scipy, boto3, catboost, joblib, scikit-learn, lightgbm, tblib, cloudpickle, psutil, dask, toolz, sortedcontainers, heapdict, zict, msgpack, distributed, gluonnlp, pyaml, scikit-optimize, typing, cython, ConfigSpace, tqdm, autogluon\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n",
      "      Successfully uninstalled scipy-1.3.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.36.1\n",
      "    Uninstalling tqdm-4.36.1:\n",
      "      Successfully uninstalled tqdm-4.36.1\n",
      "Successfully installed ConfigSpace-0.4.10 autogluon-0.0.5 bcrypt-3.1.7 boto3-1.9.187 catboost-0.21 cffi-1.14.0 cloudpickle-1.3.0 cryptography-2.8 cython-0.29.15 dask-2.6.0 distributed-2.6.0 gluonnlp-0.8.1 heapdict-1.0.1 joblib-0.14.1 lightgbm-2.3.0 msgpack-0.6.2 paramiko-2.7.1 psutil-5.6.7 pyaml-19.12.0 pycparser-2.19 pynacl-1.3.0 scikit-learn-0.21.2 scikit-optimize-0.7.1 scipy-1.4.1 sortedcontainers-2.1.0 tblib-1.6.0 toolz-0.10.0 tqdm-4.42.1 typing-3.7.4.1 zict-1.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install bokeh\n",
    "!pip install --upgrade pip\n",
    "!pip install mxnet autogluon\n",
    "!brew install libomp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. AutoGluon TabularPrediction on raw unprocessed datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Reading and getting the dataset in AutoGluon TabularPrediction friendly format\n",
    "\n",
    "We first use the __pandas__ library to read our raw unpreprocessed __review_dataset__ and split into training and testing datasets. Let's take a look of what does the dataset look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21972</th>\n",
       "      <td>Update 5/2/2011\\nOk this software is starting ...</td>\n",
       "      <td>Errors in Mortgage Calculations &amp; Software dis...</td>\n",
       "      <td>True</td>\n",
       "      <td>1303948800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>Great software product. I have used this produ...</td>\n",
       "      <td>Great software</td>\n",
       "      <td>False</td>\n",
       "      <td>1425427200</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39264</th>\n",
       "      <td>When I tried to download the Turbo Tax program...</td>\n",
       "      <td>Virus??</td>\n",
       "      <td>True</td>\n",
       "      <td>1451347200</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35413</th>\n",
       "      <td>The topo map is outdated as far as road names ...</td>\n",
       "      <td>SE topo</td>\n",
       "      <td>False</td>\n",
       "      <td>1178668800</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245</th>\n",
       "      <td>Ripped me off this last year, though I used th...</td>\n",
       "      <td>Filling out the forms is fine, especially if y...</td>\n",
       "      <td>True</td>\n",
       "      <td>1426464000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  \\\n",
       "21972  Update 5/2/2011\\nOk this software is starting ...   \n",
       "6156   Great software product. I have used this produ...   \n",
       "39264  When I tried to download the Turbo Tax program...   \n",
       "35413  The topo map is outdated as far as road names ...   \n",
       "8245   Ripped me off this last year, though I used th...   \n",
       "\n",
       "                                                 summary  verified  \\\n",
       "21972  Errors in Mortgage Calculations & Software dis...      True   \n",
       "6156                                      Great software     False   \n",
       "39264                                            Virus??      True   \n",
       "35413                                            SE topo     False   \n",
       "8245   Filling out the forms is fine, especially if y...      True   \n",
       "\n",
       "             time  rating  \n",
       "21972  1303948800     1.0  \n",
       "6156   1425427200     5.0  \n",
       "39264  1451347200     2.0  \n",
       "35413  1178668800     3.0  \n",
       "8245   1426464000     2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/NLP/review_dataset.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"log_votes\", axis =1), df[\"log_votes\"],\n",
    "                                                  test_size=0.10,  # 10% test, 90% tranining\n",
    "                                                  shuffle=True # Shuffle the whole dataset\n",
    "                                                 )\n",
    "\n",
    "pd.concat([X_train, y_train], axis = 1).to_csv('data/NLP/review_dataset_AG_training.csv', index=False)\n",
    "pd.concat([X_test, y_test], axis = 1).to_csv('data/NLP/review_dataset_AG_test.csv', index=False)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Use AutoGluon TabularPrediction to train a regressor \n",
    "\n",
    "AutoGluon can deal with a varied of tasks such as Image Classification, Object Detection, Text Classification, etc. Please see more details at [autogluon.task](https://autogluon.mxnet.io/api/autogluon.task.html). Our task in this demo is `TabularPrediction`, which is equipped to predict values in column of tabular dataset (classification or regression).\n",
    "\n",
    "\n",
    "Now, let's load the raw unpreprocessed training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: data/NLP/review_dataset_AG_training.csv | Columns = 6 / 6 | Rows = 49500 -> 49500\n",
      "Loaded data from: data/NLP/review_dataset_AG_test.csv | Columns = 6 / 6 | Rows = 5500 -> 5500\n"
     ]
    }
   ],
   "source": [
    "from autogluon import TabularPrediction as task\n",
    "\n",
    "train_data = task.Dataset(file_path='data/NLP/review_dataset_AG_training.csv')\n",
    "test_data = task.Dataset(file_path='data/NLP/review_dataset_AG_test.csv')\n",
    "\n",
    "# For speed, grab a small subset of the dataset\n",
    "train_data = train_data.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameters\n",
    "\n",
    "To train a regressor with AutoGluon `TabularPrediction`, we need to configure the `hyperparameters` parameter. By default, it is a dictionary of key-value pairs. The keys are strings that indicate which ML models to train, includes: \n",
    "- ‘NN’ (neural network), \n",
    "- ‘GBM’ (lightGBM boosted trees), \n",
    "- ‘CAT’ (CatBoost boosted trees), \n",
    "- ‘RF’ (random forest), \n",
    "- ‘XT’ (extremely randomized trees), \n",
    "- ‘KNN’ (k-nearest neighbors).\n",
    "\n",
    "And the values are dictionaries of hyperparameter settings for each model type. For example, we can define a `hyperparameters` \"hyp\" as \n",
    "\n",
    "```\n",
    "hyp = {'NN': {'num_epochs': 500}, 'GBM': {'num_boost_round': 10000}, 'CAT': {'iterations': 10000}, 'RF': {'n_estimators': 300}, 'XT': {'n_estimators': 300}, 'KNN': {}, 'custom': ['GBM']}\n",
    "```\n",
    "\n",
    "Let's define the hyperparameters for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For speed, change the default hyperparameters\n",
    "hyp = {'GBM': {'num_boost_round': 1000}, 'CAT': {'iterations': 1000}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Auto_stack\n",
    "\n",
    "Auto_stack decides whether to automatically attempt to select optimal `num_bagging_folds` and `stack_ensemble_levels` based on data properties. This can decrease the training time by up to 20x, but can produce much better results. Additionally, this can decrease inference time by up to 20x.\n",
    "\n",
    "Now we are ready to define and train our model using `fit()`, which trains neural networks and various types of tree ensembles by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20200210_195926/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20200210_195926/\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 6\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [0.         1.60943791 1.09861229 1.79175947 2.30258509 3.4657359\n",
      " 1.38629436 2.63905733 1.94591015 3.49650756]\n",
      "AutoGluon infers your prediction problem is: regression  (because dtype of label-column == float and label-values can't be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 1000 data points with 466 features\n",
      "Original Features:\n",
      "\tobject features: 2\n",
      "\tbool features: 1\n",
      "\tint features: 1\n",
      "\tfloat features: 1\n",
      "Generated Features:\n",
      "\tint features: 461\n",
      "All Features:\n",
      "\tobject features: 2\n",
      "\tbool features: 1\n",
      "\tint features: 462\n",
      "\tfloat features: 1\n",
      "\tData preprocessing and feature engineering runtime = 2.62s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: r2\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: r2\n",
      "Fitting model: LightGBMRegressor_STACKER_l0 ...\n",
      "\t0.2841\t = Validation r2 score\n",
      "\t10.18s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor_STACKER_l0 ...\n",
      "\t0.3194\t = Validation r2 score\n",
      "\t22.75s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.3208\t = Validation r2 score\n",
      "\t0.16s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMRegressor_STACKER_l1 ...\n",
      "\t0.3002\t = Validation r2 score\n",
      "\t11.0s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: CatboostRegressor_STACKER_l1 ...\n",
      "\t0.3112\t = Validation r2 score\n",
      "\t28.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l2 ...\n",
      "\t0.3257\t = Validation r2 score\n",
      "\t0.11s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 75.2s ...\n"
     ]
    }
   ],
   "source": [
    "auto_stack = True \n",
    "\n",
    "model = task.fit(train_data = train_data, label = 'log_votes', \n",
    "                 eval_metric = 'r2', auto_stack = auto_stack, hyperparameters = hyp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Evaluate performance with TabularPrediction\n",
    "\n",
    "Let's now use our trained `model` to make predictions on the test dataset using `predict()`. \n",
    "\n",
    "Then we evaluate performance using [`evaluate_predictions()`](https://autogluon.mxnet.io/api/autogluon.task.html?highlight=evaluate_predictions#autogluon.task.tabular_prediction.TabularPredictor.evaluate_predictions). Here we set `auxiliary_metrics` as True, which indicates the predictor to compute other tabular metrics in addition to the default metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: r2 on test data: 0.320081\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"r2\": 0.3200810218276856,\n",
      "    \"mean_absolute_error\": 0.5421254660779772,\n",
      "    \"explained_variance_score\": 0.32412104656348506,\n",
      "    \"r2_score\": 0.3200810218276856,\n",
      "    \"pearson_correlation\": 0.5837249356520682,\n",
      "    \"mean_squared_error\": 0.6419765336436036,\n",
      "    \"median_absolute_error\": 0.274038471246732\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_data)\n",
    "y_test = test_data['log_votes']\n",
    "performance = model.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if we want a summary of what happened during `fit()`, the `fit_summary()` will return the details of the ensemble models as below. It may create various generated summary plots in a new window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Number of models trained: 6\n",
      "Types of models trained: \n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel'}\n",
      "Validation performance of individual models: {'LightGBMRegressor_STACKER_l0': 0.28411560144152903, 'CatboostRegressor_STACKER_l0': 0.3194285529330769, 'weighted_ensemble_k0_l1': 0.32083864852375077, 'LightGBMRegressor_STACKER_l1': 0.3002416757259313, 'CatboostRegressor_STACKER_l1': 0.31119809889680494, 'weighted_ensemble_k0_l2': 0.3257069698656295}\n",
      "Best model (based on validation performance): weighted_ensemble_k0_l2\n",
      "Hyperparameter-tuning used: False\n",
      "Bagging used: True  (with 10 folds)\n",
      "Stack-ensembling used: True  (with 1 levels)\n",
      "User-specified hyperparameters:\n",
      "{'GBM': {'num_boost_round': 1000}, 'CAT': {'iterations': 1000}}\n",
      "Plot summary of models saved to file: SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = model.fit_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this summary, we can see that __AutoGluon__ trained many different types of models as well as an ensemble of the best-performing models. The summary also describes the actual models that were trained during fit and how well each model performed on the held-out validation data. \n",
    "\n",
    "We can also view what properties __AutoGluon__ automatically inferred about our prediction task, along with more details on features preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  regression\n",
      "\n",
      "AutoGluon categorized the features as:  {'nlp': ['reviewText', 'summary'], 'vectorizers': ['__nlp__.10', '__nlp__.able', '__nlp__.able to', '__nlp__.about', '__nlp__.after', '__nlp__.again', '__nlp__.all', '__nlp__.all the', '__nlp__.also', '__nlp__.always', '__nlp__.am', '__nlp__.amazon', '__nlp__.an', '__nlp__.and', '__nlp__.and have', '__nlp__.and it', '__nlp__.and the', '__nlp__.another', '__nlp__.any', '__nlp__.anything', '__nlp__.are', '__nlp__.around', '__nlp__.as', '__nlp__.as well', '__nlp__.at', '__nlp__.at all', '__nlp__.at the', '__nlp__.back', '__nlp__.back to', '__nlp__.bad', '__nlp__.be', '__nlp__.because', '__nlp__.been', '__nlp__.been using', '__nlp__.before', '__nlp__.being', '__nlp__.best', '__nlp__.better', '__nlp__.bit', '__nlp__.bought', '__nlp__.bought this', '__nlp__.business', '__nlp__.but', '__nlp__.but it', '__nlp__.buy', '__nlp__.by', '__nlp__.can', '__nlp__.can be', '__nlp__.company', '__nlp__.computer', '__nlp__.could', '__nlp__.customer', '__nlp__.data', '__nlp__.day', '__nlp__.days', '__nlp__.did', '__nlp__.did not', '__nlp__.didn', '__nlp__.different', '__nlp__.do', '__nlp__.do not', '__nlp__.does', '__nlp__.does not', '__nlp__.doesn', '__nlp__.doing', '__nlp__.don', '__nlp__.done', '__nlp__.down', '__nlp__.download', '__nlp__.downloaded', '__nlp__.easy', '__nlp__.easy to', '__nlp__.easy to use', '__nlp__.etc', '__nlp__.even', '__nlp__.ever', '__nlp__.every', '__nlp__.everything', '__nlp__.excellent', '__nlp__.far', '__nlp__.fast', '__nlp__.feature', '__nlp__.features', '__nlp__.few', '__nlp__.file', '__nlp__.files', '__nlp__.finally', '__nlp__.find', '__nlp__.fine', '__nlp__.first', '__nlp__.five', '__nlp__.five stars', '__nlp__.for', '__nlp__.for me', '__nlp__.for my', '__nlp__.for the', '__nlp__.for years', '__nlp__.found', '__nlp__.four', '__nlp__.free', '__nlp__.from', '__nlp__.from the', '__nlp__.get', '__nlp__.getting', '__nlp__.give', '__nlp__.go', '__nlp__.going', '__nlp__.good', '__nlp__.got', '__nlp__.great', '__nlp__.great product', '__nlp__.had', '__nlp__.had to', '__nlp__.happy', '__nlp__.hard', '__nlp__.has', '__nlp__.have', '__nlp__.have been', '__nlp__.have to', '__nlp__.have used', '__nlp__.haven', '__nlp__.having', '__nlp__.help', '__nlp__.highly', '__nlp__.home', '__nlp__.how', '__nlp__.how to', '__nlp__.however', '__nlp__.if', '__nlp__.if you', '__nlp__.if you are', '__nlp__.in', '__nlp__.in my', '__nlp__.in the', '__nlp__.information', '__nlp__.install', '__nlp__.installation', '__nlp__.installed', '__nlp__.internet', '__nlp__.into', '__nlp__.is', '__nlp__.is great', '__nlp__.is not', '__nlp__.is that', '__nlp__.is the', '__nlp__.is very', '__nlp__.issues', '__nlp__.it', '__nlp__.it and', '__nlp__.it does', '__nlp__.it for', '__nlp__.it has', '__nlp__.it is', '__nlp__.it to', '__nlp__.it was', '__nlp__.it will', '__nlp__.it works', '__nlp__.it would', '__nlp__.its', '__nlp__.job', '__nlp__.just', '__nlp__.keep', '__nlp__.know', '__nlp__.laptop', '__nlp__.last', '__nlp__.learn', '__nlp__.learning', '__nlp__.less', '__nlp__.let', '__nlp__.like', '__nlp__.like the', '__nlp__.little', '__nlp__.ll', '__nlp__.long', '__nlp__.look', '__nlp__.looking', '__nlp__.lot', '__nlp__.lot of', '__nlp__.love', '__nlp__.mac', '__nlp__.made', '__nlp__.make', '__nlp__.makes', '__nlp__.many', '__nlp__.me', '__nlp__.microsoft', '__nlp__.money', '__nlp__.more', '__nlp__.more than', '__nlp__.most', '__nlp__.much', '__nlp__.my', '__nlp__.my computer', '__nlp__.need', '__nlp__.need to', '__nlp__.needed', '__nlp__.never', '__nlp__.new', '__nlp__.next', '__nlp__.nice', '__nlp__.no', '__nlp__.norton', '__nlp__.not', '__nlp__.now', '__nlp__.of', '__nlp__.of my', '__nlp__.of the', '__nlp__.off', '__nlp__.office', '__nlp__.old', '__nlp__.on', '__nlp__.on my', '__nlp__.on the', '__nlp__.once', '__nlp__.one', '__nlp__.one of', '__nlp__.online', '__nlp__.only', '__nlp__.or', '__nlp__.other', '__nlp__.our', '__nlp__.out', '__nlp__.over', '__nlp__.own', '__nlp__.pay', '__nlp__.pc', '__nlp__.people', '__nlp__.pretty', '__nlp__.previous', '__nlp__.price', '__nlp__.pro', '__nlp__.problem', '__nlp__.problems', '__nlp__.process', '__nlp__.product', '__nlp__.products', '__nlp__.program', '__nlp__.programs', '__nlp__.purchase', '__nlp__.purchased', '__nlp__.quicken', '__nlp__.re', '__nlp__.really', '__nlp__.recommend', '__nlp__.return', '__nlp__.reviews', '__nlp__.right', '__nlp__.run', '__nlp__.running', '__nlp__.said', '__nlp__.same', '__nlp__.save', '__nlp__.say', '__nlp__.security', '__nlp__.see', '__nlp__.seems', '__nlp__.service', '__nlp__.set', '__nlp__.several', '__nlp__.should', '__nlp__.simple', '__nlp__.since', '__nlp__.slow', '__nlp__.so', '__nlp__.so far', '__nlp__.software', '__nlp__.software is', '__nlp__.some', '__nlp__.something', '__nlp__.star', '__nlp__.stars', '__nlp__.started', '__nlp__.still', '__nlp__.such', '__nlp__.support', '__nlp__.sure', '__nlp__.system', '__nlp__.take', '__nlp__.tax', '__nlp__.than', '__nlp__.that', '__nlp__.that it', '__nlp__.that the', '__nlp__.the', '__nlp__.the best', '__nlp__.the new', '__nlp__.the product', '__nlp__.the program', '__nlp__.the same', '__nlp__.the software', '__nlp__.their', '__nlp__.them', '__nlp__.then', '__nlp__.there', '__nlp__.there are', '__nlp__.there is', '__nlp__.these', '__nlp__.they', '__nlp__.thing', '__nlp__.things', '__nlp__.think', '__nlp__.this', '__nlp__.this is', '__nlp__.this product', '__nlp__.this program', '__nlp__.this software', '__nlp__.this year', '__nlp__.those', '__nlp__.though', '__nlp__.thought', '__nlp__.three', '__nlp__.through', '__nlp__.time', '__nlp__.to', '__nlp__.to be', '__nlp__.to buy', '__nlp__.to do', '__nlp__.to download', '__nlp__.to find', '__nlp__.to get', '__nlp__.to have', '__nlp__.to install', '__nlp__.to my', '__nlp__.to the', '__nlp__.to use', '__nlp__.too', '__nlp__.tried', '__nlp__.try', '__nlp__.trying', '__nlp__.turbo', '__nlp__.turbo tax', '__nlp__.turbotax', '__nlp__.two', '__nlp__.up', '__nlp__.update', '__nlp__.upgrade', '__nlp__.use', '__nlp__.use it', '__nlp__.use the', '__nlp__.used', '__nlp__.used to', '__nlp__.user', '__nlp__.using', '__nlp__.ve', '__nlp__.ve been', '__nlp__.version', '__nlp__.version of', '__nlp__.very', '__nlp__.virus', '__nlp__.want', '__nlp__.want to', '__nlp__.wanted', '__nlp__.was', '__nlp__.way', '__nlp__.way to', '__nlp__.we', '__nlp__.website', '__nlp__.well', '__nlp__.were', '__nlp__.what', '__nlp__.when', '__nlp__.which', '__nlp__.which is', '__nlp__.while', '__nlp__.who', '__nlp__.why', '__nlp__.will', '__nlp__.windows', '__nlp__.with', '__nlp__.with it', '__nlp__.with the', '__nlp__.with this', '__nlp__.without', '__nlp__.won', '__nlp__.work', '__nlp__.worked', '__nlp__.working', '__nlp__.works', '__nlp__.worth', '__nlp__.would', '__nlp__.would be', '__nlp__.xp', '__nlp__.year', '__nlp__.years', '__nlp__.years and', '__nlp__.you', '__nlp__.you are', '__nlp__.you can', '__nlp__.you have', '__nlp__.you need', '__nlp__.you to', '__nlp__.your', '__nlp__._total_'], 'object': ['reviewText', 'summary'], 'bool': ['verified'], 'int': ['time', 'reviewText.symbol_count./', 'reviewText.lower_ratio', 'reviewText.digit_ratio', 'reviewText.symbol_count.!', 'reviewText.symbol_ratio.@', 'summary.symbol_count.^', 'summary.symbol_count..', 'summary.capital_ratio', 'summary.symbol_ratio.;', 'reviewText.symbol_ratio..', 'summary.symbol_count.$', 'reviewText.symbol_count.?', 'summary.symbol_count.!', 'reviewText.capital_ratio', 'reviewText.symbol_count.@', 'summary.symbol_count.&', 'summary.lower_ratio', 'reviewText.symbol_ratio. ', 'reviewText.symbol_ratio.*', 'summary.digit_ratio', 'summary.special_ratio', 'reviewText.symbol_ratio.&', 'summary.symbol_count.:', 'summary.symbol_ratio.!', 'summary.symbol_ratio. ', 'reviewText.symbol_ratio.%', 'reviewText.symbol_ratio.$', 'reviewText.symbol_count.%', 'reviewText.symbol_count.;', 'summary.symbol_count.#', 'reviewText.special_ratio', 'summary.word_count', 'summary.symbol_ratio.#', 'summary.symbol_ratio./', 'reviewText.symbol_count.:', 'reviewText.symbol_count. ', 'summary.symbol_ratio.$', 'reviewText.symbol_ratio.!', 'reviewText.char_count', 'reviewText.symbol_count.-', 'summary.symbol_ratio.&', 'reviewText.symbol_ratio.=', 'reviewText.symbol_count.*', 'summary.symbol_count.?', 'summary.symbol_ratio.-', 'reviewText.symbol_ratio.?', 'reviewText.symbol_count.=', 'summary.symbol_count.*', 'summary.symbol_ratio.:', 'summary.symbol_ratio.?', 'reviewText.word_count', 'reviewText.symbol_ratio.:', 'summary.symbol_ratio.^', 'summary.symbol_count.;', 'reviewText.symbol_ratio.#', 'summary.symbol_count./', 'reviewText.symbol_ratio.-', 'reviewText.symbol_count.#', 'reviewText.symbol_ratio./', 'summary.char_count', 'reviewText.symbol_count..', 'summary.symbol_count.-', 'reviewText.symbol_count.$', 'reviewText.symbol_ratio.;', 'summary.symbol_count. ', 'summary.symbol_ratio..', 'reviewText.symbol_count.&', 'summary.symbol_ratio.*'], 'float': ['rating']}\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", model.problem_type)\n",
    "print()\n",
    "print(\"AutoGluon categorized the features as: \", model.feature_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summary: AutoGluon TabularPrediction\n",
    "\n",
    "With just a few lines of code __AutoGluon TabularPrediction__ should be able to achieve strong predictive performance on your datasets, as long as your tabular datasets are stored in a popular format like .csv.\n",
    "\n",
    "**Note**: The code below can be very computationally-intensive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AutoGluon TabularPrediction run on the full datasets!\n",
    "## WARNING: The code below can be very computationally-intensive!\n",
    "\n",
    "# from autogluon import TabularPrediction as task\n",
    "# train_data = task.Dataset(file_path='data/NLP/review_dataset_AG_training.csv')\n",
    "# test_data = task.Dataset(file_path='data/NLP/review_dataset_AG_test.csv')\n",
    "# predictor = task.fit(train_data=train_data, label='log_votes', eval_metric = 'r2')\n",
    "# performance = predictor.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "# print(\"AutoGluon categorized the features as: \", predictor.feature_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "579px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
